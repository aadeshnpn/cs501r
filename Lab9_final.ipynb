{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab9_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "x4Tx3Q4qgOza",
        "colab_type": "code",
        "outputId": "4bbb40c2-55f4-41f5-d2a0-e41e711910fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1270
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install torch torch-vision gym matplotlib numpy tqdm imageio\n",
        "! pip install pygame atari_py graphviz gym-tetris pandas"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 27kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x60b10000 @  0x7fa9335a62a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting torch-vision\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/13/4942860c32f6877def97c0b432348adce870ae613ed4eb1de10cae0bb018/torch_vision-0.1.6.dev0-py2.py3-none-any.whl\n",
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/22/4ff09745ade385ffe707fb5f053548f0f6a6e7d5e98a2b9d6c07f5b931a7/gym-0.10.9.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Collecting imageio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b4/cbb592964dfd71a9de6a5b08f882fd334fb99ae09ddc82081dbb2f718c81/imageio-2.4.1.tar.gz (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.7)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.0.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.46)\n",
            "Building wheels for collected packages: gym, imageio\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6c/3a/0e/b86dee98876bb56cdb482cc1f72201035e46d1baf69d10d028\n",
            "  Running setup.py bdist_wheel for imageio ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e0/43/31/605de9372ceaf657f152d3d5e82f42cf265d81db8bbe63cde1\n",
            "Successfully built gym imageio\n",
            "Installing collected packages: torch, torch-vision, pyglet, gym, imageio\n",
            "Successfully installed gym-0.10.9 imageio-2.4.1 pyglet-1.3.2 torch-1.0.0 torch-vision-0.1.6.dev0\n",
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/5e/fb7c85304ad1fd52008fd25fce97a7f59e6147ae97378afc86cf0f5d9146/pygame-1.9.4-cp36-cp36m-manylinux1_x86_64.whl (12.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.1MB 3.8MB/s \n",
            "\u001b[?25hCollecting atari_py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/23/96ce488af867646277d91c3c9a1f328a5452240fe51df0a5fdf9211d76e0/atari_py-0.1.7-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.6MB 13.2MB/s \n",
            "\u001b[?25hCollecting graphviz\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
            "Collecting gym-tetris\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/05/a00bab9be1b6e3000aaee8ab3554c46714ab85fcf39c0a08cf113617e1f8/gym_tetris-1.2.10-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from atari_py) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from atari_py) (1.11.0)\n",
            "Requirement already satisfied: tqdm>=4.19.5 in /usr/local/lib/python3.6/dist-packages (from gym-tetris) (4.28.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from gym-tetris) (2.1.2)\n",
            "Requirement already satisfied: pyglet>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from gym-tetris) (1.3.2)\n",
            "Requirement already satisfied: opencv-python>=3.4.0.12 in /usr/local/lib/python3.6/dist-packages (from gym-tetris) (3.4.4.19)\n",
            "Requirement already satisfied: gym>=0.10.5 in /usr/local/lib/python3.6/dist-packages (from gym-tetris) (0.10.9)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.7)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->gym-tetris) (2.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->gym-tetris) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.3.2->gym-tetris) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.10.5->gym-tetris) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.10.5->gym-tetris) (2.18.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym>=0.10.5->gym-tetris) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym>=0.10.5->gym-tetris) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym>=0.10.5->gym-tetris) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym>=0.10.5->gym-tetris) (2.6)\n",
            "Installing collected packages: pygame, atari-py, graphviz, gym-tetris\n",
            "Successfully installed atari-py-0.1.7 graphviz-0.10.1 gym-tetris-1.2.10 pygame-1.9.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h2zubiUNyrZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Instruct matplotlib to draw inline\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import pdb\n",
        "%matplotlib inline\n",
        "\n",
        "# Ploting the train loss   \n",
        "def plotloss(vloss, ploss, rewards):\n",
        "    #x = np.linspace(0, 2, 100)\n",
        "    x = range(len(rewards))\n",
        "    #print (len(rewards), len(vloss))\n",
        "    #plt.plot(x, vloss, label='Value loss')\n",
        "    #plt.plot(x, ploss, label='Policy loss')\n",
        "    #pdb.set_trace()\n",
        "    plt.plot(x, rewards, label='Rewards')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Reward')\n",
        "\n",
        "    plt.title(\"Average Rewards per Epoch\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()    \n",
        "    \n",
        "\n",
        "def make_gif(rollout, filename):\n",
        "    with imageio.get_writer(filename, mode='I', duration=1 / 30) as writer:\n",
        "        for x in rollout:\n",
        "          writer.append_data((x[0][:, :, 0] * 255).astype(np.uint8))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hwTB4mA2gk5v",
        "colab_type": "code",
        "outputId": "7214723f-1e56-44a9-cee4-9b9d98008c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.categorical import Categorical\n",
        "import gym\n",
        "import gym_tetris\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from queue import Queue\n",
        "from threading import Thread\n",
        "from itertools import chain\n",
        "\n",
        "# device=torch.device('cpu')\n",
        "      \n",
        "# Combining the actor critic in same class\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super().__init__()\n",
        "        self.actor = nn.Sequential(\n",
        "        nn.Linear(state_size, 10),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(10, 10),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(10, 10),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(10, action_size)\n",
        "        )\n",
        "        # self.dist = Categorical(action_size, action_size)\n",
        "        \n",
        "    def forward(self, obs):\n",
        "        x = self.actor(obs)\n",
        "        \n",
        "        prob = F.log_softmax(x, dim=1)\n",
        "        # prob = F.softmax(x, dim=1)\n",
        "        # dist = self.dist(prob)\n",
        "        # action = dist.sample()\n",
        "        \n",
        "        self.dist = Categorical(logits=prob)\n",
        "        action = self.dist.sample()              \n",
        "        return prob, action     \n",
        "\n",
        "class Critic(nn.Module):\n",
        "  def __init__(self, state_size, action_size):\n",
        "    super().__init__()\n",
        "    self.critic = nn.Sequential(\n",
        "      nn.Linear(state_size, 10),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(10, 10),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(10, 10),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(10, 1)\n",
        "      )\n",
        "    \n",
        "  def forward(self, obs):\n",
        "    value = self.critic(obs)\n",
        "    return value"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.4\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9zUv9JJSiM4C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ExperienceDataset(Dataset):\n",
        "    def __init__(self, experience):\n",
        "        super(ExperienceDataset, self).__init__()\n",
        "        self._exp = []\n",
        "        for x in experience:\n",
        "            self._exp.extend(x)\n",
        "        self._length = len(self._exp)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self._exp[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._length\n",
        "      \n",
        "def state_returns(states, gamma):\n",
        "    curr_return = 0\n",
        "    for i in reversed(range(len(states))):\n",
        "        state, dist, action, reward = states[i]\n",
        "        ret = reward + gamma * curr_return\n",
        "        states[i] = (state, dist, action, reward, ret)\n",
        "        curr_return = ret\n",
        "    return states\n",
        "      \n",
        "\n",
        "def collect_episodes(envname, actor, num_rollouts, max_eplen, gamma):\n",
        "  episodes = []\n",
        "  rewards = []\n",
        "  # just to eval the model\n",
        "  actor.eval()\n",
        "  env = gym.make(envname)\n",
        "  for _ in range(num_rollouts):\n",
        "    episode = []\n",
        "    # env = gym.make(envname)\n",
        "    initial_state = env.reset()\n",
        "    total_reward = 0\n",
        "    for _ in range(max_eplen):\n",
        "      # Convert the environment state to pytorch tensor\n",
        "      initial_state_tensor = fromnp(initial_state, device)\n",
        "      # Pass the tensor to Actor Critic NN to get the distribution overaction\n",
        "      # and best action to apply\n",
        "      dist, action = actor(initial_state_tensor)\n",
        "      # dist, action = dist[0], action[0]\n",
        "      # Use the action from the NN to go to next state\n",
        "      state, reward, done, info = env.step(action.item())\n",
        "      # Add the state, distribution, action and reward to the list\n",
        "      episode.append((initial_state, dist.cpu().detach().numpy(), action.detach(), reward))\n",
        "      # episode.append((initial_state, dist.cpu().detach().numpy(), action, reward))\n",
        "      total_reward += reward\n",
        "      if done:\n",
        "        break\n",
        "      initial_state = state\n",
        "    episode = state_returns(episode, gamma)\n",
        "    episodes.append(episode)\n",
        "    rewards.append(total_reward)\n",
        "  return (episodes, rewards)\n",
        "        \n",
        "def fromnp(data, device):\n",
        "    return torch.from_numpy(data).float().unsqueeze(0).to(device)\n",
        "\n",
        "def tensorbatch(tensor, device):\n",
        "    return tensor.detach().float().to(device)   \n",
        "  \n",
        "def multinomial_likelihood(dist, idx):\n",
        "    return dist[range(dist.shape[0]), idx.long()[:, 0]].unsqueeze(1) \n",
        "\n",
        "#def multinomial_likelihood(dist, idx):\n",
        "#    return dist[:, idx.long()[:, 0]].unsqueeze(1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MjUgXAHgiWmF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For parallel execution\n",
        "#from joblib import Parallel, delayed \n",
        "#from multiprocessing import Pool\n",
        "\n",
        "def algo(envs, actor, critic, epochs=50, episodeperenv=200, max_episode_len=200, discount=0.99, batch_size=128, epsilon=0.2, device=torch.device('cpu'), lr=1e-3):\n",
        "  # Set up optimizer and loss function\n",
        "  params = chain(actor.parameters(), critic.parameters())\n",
        "  optimizer = optim.Adam(params, lr=lr, betas=(0.9, 0.999), weight_decay=0.01)\n",
        "  value_loss = nn.MSELoss()\n",
        "  # Gif\n",
        "  # gif_epoch = 5\n",
        "  # Upper and lower bound for ppo\n",
        "  ppo_lb = 1 - epsilon\n",
        "  ppo_ub = 1 + epsilon\n",
        "  \n",
        "  # Progress bar\n",
        "  loop = tqdm(total=epochs, position=0, leave=False)\n",
        "  \n",
        "  vloss = []\n",
        "  ploss = []\n",
        "  rewardslist = []\n",
        "  \n",
        "  for epoch in range(epochs):    \n",
        "    # Collect experiences\n",
        "    episodes, rewards = collect_episodes(\n",
        "        envs, actor, episodeperenv, max_episode_len, discount)    \n",
        "    # print (len(rewards), rewards)\n",
        "    avgreward = sum(rewards) / len(rewards)\n",
        "    # print (avgreward.shape)\n",
        "    # Update time\n",
        "    experience_dataset = ExperienceDataset(episodes)\n",
        "    data_loader = DataLoader(experience_dataset, num_workers=0, batch_size=batch_size,\n",
        "                                 shuffle=True,\n",
        "                                 pin_memory=True)\n",
        "    avg_policy_loss = 0\n",
        "    avg_val_loss = 0   \n",
        "\n",
        "    for _ in range(5):\n",
        "      avg_policy_loss = 0\n",
        "      avg_val_loss = 0\n",
        "      for state, dist, old_action, reward, ret in data_loader:\n",
        "        #print (state.shape, dist.shape, old_action.shape, reward.shape, ret.shape)\n",
        "        tensor_state = tensorbatch(state, device)\n",
        "        old_dist = tensorbatch(dist, device).squeeze()\n",
        "        old_action = tensorbatch(old_action, device)\n",
        "        ret = tensorbatch(ret, device).unsqueeze(1)\n",
        "        \n",
        "        # ratio  or important sampling\n",
        "        curr_prob, _ = actor(tensor_state)\n",
        "        # print (act.shape)\n",
        "        #curr_prob = Categorical(logits=curr_dist).log_prob(old_action)\n",
        "        #old_prob = Categorical(logits=old_dist).log_prob(old_action)\n",
        "        # print (curr_dist.shape, old_dist.shape, old_action.shape)\n",
        "        \n",
        "        curr_prob = multinomial_likelihood(curr_prob, old_action)\n",
        "        old_prob = multinomial_likelihood(old_dist, old_action)\n",
        "        \n",
        "        # ratio = (curr_prob / old_prob)       \n",
        "        ratio = torch.exp(curr_prob - old_prob)\n",
        "        #print ('ratio', ratio)\n",
        "        \n",
        "        exp_ret = critic(tensor_state)\n",
        "        # Value loss\n",
        "        val_loss =  value_loss(exp_ret, ret)\n",
        "        \n",
        "        # Policy loss from the paper\n",
        "        adv = ret - exp_ret.detach()\n",
        "        # adv = (adv - adv.mean()) / (adv.std() + 1e-5)\n",
        "        lhs = ratio * adv\n",
        "        # Clip\n",
        "        rhs = torch.clamp(ratio, ppo_lb, ppo_ub) * adv\n",
        "        policy_loss = -torch.mean(torch.min(lhs, rhs))\n",
        "        \n",
        "        # Losses\n",
        "        avg_val_loss += val_loss.item()\n",
        "        avg_policy_loss += policy_loss.item()\n",
        "        \n",
        "        # Learning\n",
        "        totloss = policy_loss + val_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        totloss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm(params, 10)\n",
        "        # Take a step\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Log info\n",
        "      avg_val_loss /= len(data_loader)\n",
        "      avg_policy_loss /= len(data_loader)\n",
        "    loop.set_description(\n",
        "      'avg reward: % 6.2f, value loss: % 6.2f, policy loss: % 6.2f' % (avgreward, avg_val_loss, avg_policy_loss))      \n",
        "      \n",
        "    loop.update(1)\n",
        "    vloss.append(avg_val_loss)\n",
        "    ploss.append(avg_policy_loss)\n",
        "    rewardslist.append(avgreward)\n",
        "\n",
        "  \n",
        "  return vloss, ploss, rewardslist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LK9SHgoL7CYB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cartpole environment"
      ]
    },
    {
      "metadata": {
        "id": "Rqp2rndfihRX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run(proc):\n",
        "  envs = []\n",
        "  for i in range(proc):\n",
        "    env = gym.make('CartPole-v0')\n",
        "    state_size = env.observation_space.shape[0]\n",
        "    action_size = env.action_space.n\n",
        "    envs.append(env)    \n",
        "  actor = Actor(state_size, action_size)\n",
        "  critic = Critic(state_size, action_size)\n",
        "  #ac.cuda()\n",
        "  vloss, ploss, rewards = algo('CartPole-v0', actor, critic)\n",
        "  plotloss(vloss, ploss, rewards)    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BwEOj0w6AQtG",
        "colab_type": "code",
        "outputId": "c8b7557d-3b92-4cc5-8bb1-a07565ae8a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "cell_type": "code",
      "source": [
        "run(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n",
            "avg reward:  198.93, value loss:  232.04, policy loss:   0.02: 100%|██████████| 50/50 [17:39<00:00, 23.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f210c490ba8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "aA-aHhkU1RpO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Breakout"
      ]
    },
    {
      "metadata": {
        "id": "TiT5Msw1W13G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda')\n",
        "\n",
        "def to_grayscale(img):\n",
        "    return np.mean(img, axis=2).astype(np.float32)\n",
        "\n",
        "def preprocess(img):\n",
        "    return to_grayscale(img)\n",
        "  \n",
        "class GameWrapper():\n",
        "  def __init__(self, name='BreakoutDeterministic-v4', history=5):\n",
        "    super(GameWrapper, self).__init__()\n",
        "    self.env = gym.make(name)\n",
        "    self.res = (210, 160)\n",
        "    self.history = history\n",
        "    self.states = np.zeros((self.res[0], self.res[1], history), dtype=np.float32)\n",
        "    \n",
        "  def step(self, a):\n",
        "    s,r,d,i = self.env.step(a)\n",
        "    self.process(s)\n",
        "    return self.states, r, d, i\n",
        "  \n",
        "  def reset(self):\n",
        "    self.states = np.zeros((self.res[0], self.res[1], self.history), dtype=np.float32)\n",
        "    s = self.env.reset()\n",
        "    #print (self.env.reset().shape)\n",
        "    self.process(s)\n",
        "    return self.states\n",
        "  \n",
        "  def process(self, s):\n",
        "    self.states = np.roll(self.states, 1, axis=2)\n",
        "    self.states[:,:,0] = preprocess(s)\n",
        "    \n",
        "    \n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Input image: [n, 3, 430, 330]\n",
        "        # Input image :[n, 3, 210, 160]\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(5, 16, 3, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, 2, stride=2),  \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),  \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 2, stride=2),  \n",
        "            nn.ReLU()\n",
        "            #nn.Conv2d(32, 64, 3, padding=1),  \n",
        "            #nn.ReLU(),\n",
        "            #nn.Conv2d(64, 128, 2, stride=2), # 128*26*20\n",
        "            #nn.ReLU()\n",
        "            #nn.Conv2d(128, 128, 2, stride=2),\n",
        "            #nn.ReLU(),\n",
        "            #nn.Conv2d(128, 128, 2, stride=2) #128, 6, 5 ##128, 13, 10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute((0, 3, 1, 2))\n",
        "        #print('states', x.shape)\n",
        "        states = self.conv(x)\n",
        "        #print ('after state shape', states.shape)\n",
        "        return states.view((-1, 128 * 26 * 20))\n",
        "      \n",
        "      \n",
        "# Combining the actor critic in same class\n",
        "class ActorTetris(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super().__init__()\n",
        "        self.actor = nn.Sequential(\n",
        "        nn.Linear(128 * 26 * 20, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, action_size)\n",
        "        )\n",
        "        # self.dist = Categorical(action_size, action_size)\n",
        "        \n",
        "    def forward(self, obs):\n",
        "        x = self.actor(obs)\n",
        "        \n",
        "        prob = F.log_softmax(x, dim=1)\n",
        "        # prob = F.softmax(x, dim=1)\n",
        "        # dist = self.dist(prob)\n",
        "        # action = dist.sample()\n",
        "        \n",
        "        self.dist = Categorical(logits=prob)\n",
        "        action = self.dist.sample()              \n",
        "        return prob, action   \n",
        "\n",
        "      \n",
        "class CriticTetris(nn.Module):\n",
        "  def __init__(self, state_size, action_size):\n",
        "    super().__init__()\n",
        "    self.critic = nn.Sequential(\n",
        "      nn.Linear(128 * 26 * 20, 100),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(100, 100),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(100, 100),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(100, 1)\n",
        "      )\n",
        "    \n",
        "  def forward(self, obs):\n",
        "    value = self.critic(obs)\n",
        "    return value\n",
        "          \n",
        "def fromnp(data, device):\n",
        "    return torch.from_numpy(data).float().unsqueeze(0).to(device)\n",
        "\n",
        "def tensorbatch(tensor, device):\n",
        "    return tensor.detach().float().to(device)   \n",
        "  \n",
        "def multinomial_likelihood(dist, idx):\n",
        "    return dist[range(dist.shape[0]), idx.long()[:, 0]].unsqueeze(1)   \n",
        "\n",
        "def collect_episodes_tetris(envname, actor, cnn, num_rollouts, max_eplen, gamma, exp_q, reward_q):\n",
        "  episodes = []\n",
        "  rewards = []\n",
        "  # just to eval the model\n",
        "  actor.eval()\n",
        "  cnn.eval()\n",
        "  #env = gym.make(envname)\n",
        "  env = GameWrapper(envname)\n",
        "  \n",
        "  from gym import wrappers\n",
        "  #env = wrappers.Monitor(env.env, '/tmp/',video_callable=False, force=True )\n",
        "  \n",
        "  for _ in range(num_rollouts):\n",
        "    episode = []\n",
        "    # env = gym.make(envname)\n",
        "    # env = GameWrapper(envname)\n",
        "    initial_state = env.reset()\n",
        "    total_reward = 0\n",
        "    for _ in range(max_eplen):\n",
        "      # Convert the environment state to pytorch tensor\n",
        "      initial_state_tensor = fromnp(initial_state, device)\n",
        "      # Pass the state from the environment to CNN\n",
        "      initial_state_tensor = cnn(initial_state_tensor)\n",
        "      # Pass the tensor to Actor Critic NN to get the distribution overaction\n",
        "      # and best action to apply\n",
        "      dist, action = actor(initial_state_tensor)\n",
        "      # dist, action = dist[0], action[0]\n",
        "      # Use the action from the NN to go to next state\n",
        "      # print (action.item())\n",
        "      state, reward, done, info = env.step(action.item())\n",
        "      # Add the state, distribution, action and reward to the list\n",
        "      episode.append((initial_state, dist.cpu().detach().numpy(), action.detach(), reward))\n",
        "      # episode.append((initial_state, dist.cpu().detach().numpy(), action, reward))\n",
        "      total_reward += reward\n",
        "      # print ('rewards', reward, total_reward)\n",
        "      if done:\n",
        "        break\n",
        "      initial_state = state\n",
        "      \n",
        "    # env.close()\n",
        "    episode = state_returns(episode, gamma)\n",
        "    #episodes.append(episode)\n",
        "    #rewards.append(total_reward)\n",
        "    exp_q.put(episode)\n",
        "    reward_q.put(total_reward)\n",
        "  #return (episodes, rewards)  \n",
        "\n",
        "\n",
        "def algo_tetris(envs, actor, critic, cnn=None, epochs=600, episodeperenv=8, max_episode_len=400, discount=0.99, batch_size=128, epsilon=0.2, device=torch.device('cpu'), lr=1e-3):\n",
        "  # Set up optimizer and loss function\n",
        "  params = chain(actor.parameters(), critic.parameters(), cnn.parameters())\n",
        "  optimizer = optim.Adam(params, lr=lr, betas=(0.9, 0.999), weight_decay=0.01)\n",
        "  value_loss = nn.MSELoss(reduction='sum')\n",
        "  # Gif\n",
        "  # gif_epoch = 5\n",
        "  # Upper and lower bound for ppo\n",
        "  ppo_lb = 1 - epsilon\n",
        "  ppo_ub = 1 + epsilon\n",
        "  \n",
        "  # Progress bar\n",
        "  loop = tqdm(total=epochs, position=0, leave=False)\n",
        "  statsfile = 'final.csv'\n",
        "  with open(statsfile, 'w') as f:\n",
        "    f.write('avgreward')\n",
        "    \n",
        "  vloss = []\n",
        "  ploss = []\n",
        "  rewardslist = []\n",
        "  #import torch.multiprocessing as mp\n",
        "  #cnn.share_memory()\n",
        "  #actor.share_memory()\n",
        "  for epoch in range(epochs):    \n",
        "    # Collect experiences    \n",
        "    #pool = Pool(processes=16)\n",
        "    #results = [pool.apply_async(collect_episodes_tetris, args=(\n",
        "    #    envs, actor, cnn, episodeperenv, max_episode_len, discount)\n",
        "    #                           ) for i in range(16)]\n",
        "    #output = [p.get() for p in results]\n",
        "    #episodes, rewards = zip(*output)\n",
        "    #processes = []\n",
        "    #for p in range(16):\n",
        "    #  proc = mp.Process(target=collect_episodes_tetris, args=(envs, actor, cnn, episodeperenv, max_episode_len, discount))\n",
        "    #  proc.start()\n",
        "    #  processes.append(proc)\n",
        "      \n",
        "    #for p in processes:\n",
        "    #  p.join()\n",
        "    exp_q = Queue()\n",
        "    reward_q= Queue()\n",
        "    threads = [Thread(target=collect_episodes_tetris, args=(\n",
        "        envs, actor, cnn, episodeperenv, max_episode_len, discount, exp_q, reward_q )) for i in range(4)]\n",
        "    for x in threads:\n",
        "        x.start()\n",
        "    for x in threads:\n",
        "        x.join()\n",
        "\n",
        "    # Collect the experience\n",
        "    episodes = list(exp_q.queue)\n",
        "    avgreward = sum(reward_q.queue) / reward_q.qsize()      \n",
        "    #episodes, rewards = collect_episodes_tetris(\n",
        "    #    envs, actor, cnn, episodeperenv, max_episode_len, discount)\n",
        "    \n",
        "    # print (len(rewards), rewards)\n",
        "    #avgreward = sum(rewards) / len(rewards)\n",
        "    \n",
        "    # print (avgreward.shape)\n",
        "    # Update time\n",
        "    experience_dataset = ExperienceDataset(episodes)\n",
        "    data_loader = DataLoader(experience_dataset, num_workers=0, batch_size=batch_size,\n",
        "                                 shuffle=True,\n",
        "                                 pin_memory=False)\n",
        "    avg_policy_loss = 0\n",
        "    avg_val_loss = 0   \n",
        "    if epoch == 0 :\n",
        "      make_gif(episodes[0], 'breakout' + '%d.gif' % epoch)\n",
        "    for _ in range(4):\n",
        "      avg_policy_loss = 0\n",
        "      avg_val_loss = 0\n",
        "      for state, dist, old_action, reward, ret in data_loader:\n",
        "        #print (state.shape, dist.shape, old_action.shape, reward.shape, ret.shape)\n",
        "        tensor_state = tensorbatch(state, device)\n",
        "        old_dist = tensorbatch(dist, device).squeeze()\n",
        "        old_action = tensorbatch(old_action, device)\n",
        "        ret = tensorbatch(ret, device).unsqueeze(1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        # Pass the state through the cnn\n",
        "        # print (tensor_state.shape, type(tensor_state))\n",
        "        tensor_state = cnn(tensor_state.cuda())\n",
        "        \n",
        "        # ratio  or important sampling\n",
        "        curr_prob, _= actor(tensor_state.cuda())\n",
        "        # print (act.shape)\n",
        "        #curr_prob = Categorical(logits=curr_dist).log_prob(old_action)\n",
        "        #old_prob = Categorical(logits=old_dist).log_prob(old_action)\n",
        "        # print (curr_dist.shape, old_dist.shape, old_action.shape)\n",
        "        try:\n",
        "          curr_prob = multinomial_likelihood(curr_prob, old_action)\n",
        "          old_prob = multinomial_likelihood(old_dist, old_action)\n",
        "        except IndexError:\n",
        "          break\n",
        "        \n",
        "        # ratio = (curr_prob.cuda() / old_prob.cuda())       \n",
        "        ratio = torch.exp(curr_prob.cuda() - old_prob.cuda())\n",
        "        #print ('ratio', ratio)\n",
        "        \n",
        "        exp_ret = critic(tensor_state.cuda())\n",
        "        # Value loss\n",
        "        # print ('return', exp_ret, ret)\n",
        "        val_loss =  value_loss(exp_ret.cuda(), ret.cuda())\n",
        "        \n",
        "        # Policy loss from the paper\n",
        "        # print (type(ret), type(exp_ret))\n",
        "        adv = ret.cuda() - exp_ret.detach()\n",
        "        # adv = (adv - adv.mean()) / (adv.std() + 1e-5)\n",
        "        lhs = ratio * adv\n",
        "        # Clip\n",
        "        rhs = torch.clamp(ratio, ppo_lb, ppo_ub) * adv\n",
        "        policy_loss = -torch.mean(torch.min(lhs, rhs))\n",
        "        \n",
        "        # Losses\n",
        "        avg_val_loss += val_loss.item()\n",
        "        avg_policy_loss += policy_loss.item()\n",
        "        \n",
        "        # Learning\n",
        "        totloss = policy_loss + val_loss #+ entropy\n",
        "        \n",
        "        \n",
        "        totloss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm(params, 10)\n",
        "        # Take a step\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Log info\n",
        "      avg_val_loss /= len(data_loader)\n",
        "      avg_policy_loss /= len(data_loader)\n",
        "    loop.set_description(\n",
        "      'avg reward: % 6.2f, value loss: % 6.2f, policy loss: % 6.2f' % (avgreward, avg_val_loss, avg_policy_loss))      \n",
        "    \n",
        "    with open(statsfile, 'a+') as f:\n",
        "      f.write('%6.2f\\n' % (avgreward))\n",
        "      \n",
        "    loop.update(1)\n",
        "    #vloss.append(avg_val_loss)\n",
        "    #ploss.append(avg_policy_loss)\n",
        "    rewardslist.append(avgreward)    \n",
        "    make_gif(episodes[0], 'breakout' + '%d.gif' % epoch)\n",
        "  #plotloss(vloss, ploss, rewardslist) \n",
        "  return vloss, ploss, rewardslist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fu-WZvEu1TbE",
        "colab_type": "code",
        "outputId": "afb004e6-2483-43e2-eb4f-8fa8eecba774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  def run(proc):\n",
        "  envs = gym_tetris.make('Tetris-v0')\n",
        "  state_size = envs.observation_space.shape\n",
        "  action_size = envs.action_space.n\n",
        "  print (state_size, action_size)\n",
        "  cnn = CNN()\n",
        "  cnn = cnn.cuda()\n",
        "  # rand = torch.empty((2, 430, 330, 3))\n",
        "  # state = cnn(rand)\n",
        "  \n",
        "  actor = ActorTetris(state_size, action_size)\n",
        "  critic = CriticTetris(state_size, action_size)\n",
        "  actor = actor.cuda()\n",
        "  critic = critic.cuda()\n",
        "  vloss, ploss, rewards = algo_tetris('Tetris-v0', actor, critic, cnn)\n",
        "  #plotloss(vloss, ploss, rewards)    \n",
        "  #collect_experiences(envs, 16, ac)\n",
        "\n",
        "run(2)\n",
        "\"\"\"\n",
        "\n",
        "def run(proc):\n",
        "  envs = gym_tetris.make('BreakoutDeterministic-v4')\n",
        "  #envs = gym_tetris.make('Breakout-v0')\n",
        "  # state_size = envs.observation_space.shape\n",
        "  state_size = (210, 160, 4)\n",
        "  action_size = envs.action_space.n\n",
        "  print (state_size, action_size)\n",
        "  print (envs.action_space)\n",
        "  \n",
        "  cnn = CNN()\n",
        "  cnn = cnn.cuda()\n",
        "  # rand = torch.empty((2, 430, 330, 3))\n",
        "  # state = cnn(rand)\n",
        "  \n",
        "  actor = ActorTetris(state_size, action_size)\n",
        "  critic = CriticTetris(state_size, action_size)\n",
        "  actor = actor.cuda()\n",
        "  critic = critic.cuda()\n",
        "  vloss, ploss, rewards = algo_tetris('BreakoutDeterministic-v4', actor, critic, cnn)\n",
        "  plotloss(vloss, ploss, rewards)    \n",
        "\n",
        "run(2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(210, 160, 4) 4\n",
            "Discrete(4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "avg reward:   3.25, value loss:  10.64, policy loss:  -0.00:   1%|▏         | 8/600 [10:56<14:08:31, 86.00s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "a5nc6n2tRSot",
        "colab_type": "code",
        "outputId": "a79533d2-a303-4ef5-a4fc-9a93d6405986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot the results form the file is the run is stopped in the middle\n",
        "import pandas as pd\n",
        "data = pd.read_csv('final.csv', skipinitialspace=True)\n",
        "plotloss(None, None, data) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbf10bee2e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "C5ocq6WQHW9l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "files.download('breakout0.gif') \n",
        "#!ls\n",
        "#nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CxK4l73KCc_I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('breakout6.gif') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sD8IA0HvKjWq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Breakout \n",
        "### epoch 0\n",
        "![sample output1](breakout0.gif)\n",
        "\n",
        "### epoch 6\n",
        "![sample output1](breakout6.gif)"
      ]
    },
    {
      "metadata": {
        "id": "84LgTO2u7GQw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Acrobot"
      ]
    },
    {
      "metadata": {
        "id": "LvW236clBEOy",
        "colab_type": "code",
        "outputId": "90185c04-45d5-4b34-90ca-23420083d8cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "def run(proc):\n",
        "  envs = []\n",
        "  for i in range(proc):\n",
        "    env = gym.make('MountainCar-v0')\n",
        "    state_size = env.observation_space.shape[0]\n",
        "    action_size = env.action_space.n\n",
        "    envs.append(env)    \n",
        "  actor = Actor(state_size, action_size)\n",
        "  critic = Critic(state_size, action_size)\n",
        "  #ac.cuda()\n",
        "  vloss, ploss, rewards = algo('MountainCar-v0', actor, critic)\n",
        "  plotloss(vloss, ploss, rewards)    \n",
        "  #collect_experiences(envs, 16, ac)\n",
        "\n",
        "run(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-85756f186018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m#collect_experiences(envs, 16, ac)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-85756f186018>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(proc)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0menvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MountainCar-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mstate_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maction_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ECPMJLrCGAPd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Car Racing"
      ]
    },
    {
      "metadata": {
        "id": "B3TfVrLY-un6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run(proc):\n",
        "  envs = []\n",
        "  for i in range(proc):\n",
        "    env = gym.make('CarRacing-v0')\n",
        "    state_size = env.observation_space.shape[0]\n",
        "    action_size = env.action_space.n\n",
        "    envs.append(env)    \n",
        "  ac = ActorCritic(state_size, action_size)\n",
        "  #ac.cuda()\n",
        "  vloss, ploss, rewards = algo(envs, ac)\n",
        "  plotloss(vloss, ploss, rewards)    \n",
        "  #collect_experiences(envs, 16, ac)\n",
        "  \n",
        "run(16)  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2XkAX8nlGG-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t6i3zaFjqTQT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}