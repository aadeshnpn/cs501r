{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Va6ZYIOujMbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "814495e2-ad8d-4c2b-c1dc-13e33a629c81"
      },
      "cell_type": "code",
      "source": [
        "# Install part\n",
        "!pip install torch torchvision matplotlib tqdm numpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 30kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58d54000 @  0x7f71f4c391c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 15.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.26.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.5)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.5)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.2.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSD1kNURH6fF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Deep Neural nets\n",
        "* 512,314,830 trainable parameters\n",
        "* User-defined cross-entropy loss and Conv2d function as PyTorch module\n",
        "* Different types of initialization methods\n",
        "\n",
        "#### Part 0, 1 and 2 "
      ]
    },
    {
      "metadata": {
        "id": "CbElX6k_jvWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "e9a1c304-2311-4d04-dd46-e7e0141e60ed"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pdb\n",
        "\n",
        "# Instruct matplotlib to draw inline\n",
        "%matplotlib inline\n",
        "\n",
        "# See if the cuda is avaliable and store it in device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def orthogonal_weights(dims):\n",
        "  # Using SVD to find the orthogonal matrices\n",
        "  X = np.random.random(dims)\n",
        "  U,_,Vt = np.linalg.svd(X, full_matrices=False)\n",
        "  W = Vt.reshape(dims)\n",
        "  return torch.from_numpy(W.astype(np.float32))\n",
        "\n",
        "def uniform_weights(min, max, dims):\n",
        "  # numpy function uniform and convert to torch Tensor\n",
        "  return torch.from_numpy(np.random.uniform(min, max, size=dims).astype(np.float32))\n",
        "\n",
        "def he_weights(fanin, fanout, dims):\n",
        "  # Define variance and mean and then call numpy function \n",
        "  var = 2.0 / (fanin + fanout)\n",
        "  mean = 0\n",
        "  # Use numpy function\n",
        "  return torch.from_numpy(np.random.normal(mean, var, dims).astype(np.float32))\n",
        "\n",
        "\n",
        "class CrossEntropyLoss(nn.Module):\n",
        "  def __init__(self, input=None, target=None, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='elementwise_mean'):\n",
        "  #  # self.init_params = locals()\n",
        "    super(CrossEntropyLoss, self).__init__()\n",
        "    self.__dict__.update(locals())\n",
        "\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    # Computing the exponent function\n",
        "    norminput = input - torch.max(input , (1), keepdim=True)[0]\n",
        "    expval = torch.exp(norminput)\n",
        "    # Find the softmax\n",
        "    softmax =  expval / (torch.sum(expval, (1), keepdim=True))\n",
        "    # Find the predicted values\n",
        "    indx = torch.argmax(softmax, dim=1)\n",
        "    b = range(softmax.shape[0])\n",
        "    # Find the score related to the predicted values\n",
        "    score = softmax[b, indx]\n",
        "    # Find how many prediction matched\n",
        "    match = indx != target\n",
        "    match = match.type(torch.cuda.FloatTensor)\n",
        "    # Compute sparce cross entropy loss\n",
        "    loss = (match * torch.log(score))\n",
        "    #print (score)\n",
        "    #pdb.set_trace()\n",
        "    # Return loss\n",
        "    return -torch.mean(loss)\n",
        "\n",
        "\n",
        "  def extra_repr(self):\n",
        "    pass\n",
        "\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, intiweight='he'):\n",
        "    ## Three types of init possible: he, uf, ot \n",
        "    # self.init_params = locals()\n",
        "    self.__dict__.update(locals())\n",
        "    super(Conv2d, self).__init__()\n",
        "    \n",
        "    # Define the dimensions needed on this layer\n",
        "    weight_dims = (self.out_channels, self.in_channels, *kernel_size)\n",
        "    \n",
        "    # Define the Tensor parameter weight and bias \n",
        "    self.weight = Parameter(torch.Tensor(self.out_channels, self.in_channels, *kernel_size))\n",
        "    self.bias = Parameter(torch.Tensor(out_channels))    \n",
        "    \n",
        "    # Based on which type of initilization to do init the weights and bias\n",
        "    if intiweight == 'he':      \n",
        "      self.weight.data = he_weights(in_channels, out_channels, weight_dims)\n",
        "\n",
        "      self.bias.data = he_weights(in_channels, out_channels, out_channels)\n",
        "    elif intiweight == 'uf':     \n",
        "      self.weight.data = uniform_weights(-1, 1, weight_dims)\n",
        "\n",
        "      self.bias.data = uniform_weights(0, 0, out_channels)     \n",
        "    elif intiweight == 'ot':   \n",
        "      self.weight.data = orthogonal_weights(weight_dims)\n",
        "      # Not possbile to initialize bias this way\n",
        "      #self.bias.data = orthogonal_weights(out_channels)\n",
        "      self.bias.data.uniform_(0, 0)\n",
        "    else:\n",
        "      self.weight.data.uniform_(-1, 1)\n",
        "    \n",
        "      self.bias.data.uniform_(0, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "  def extra_repr(self):\n",
        "    pass\n",
        "\n",
        "\n",
        "# Define the neural nets module which inherits the nn.Module\n",
        "class ConvNetwork(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(ConvNetwork, self).__init__()\n",
        "        x, y = dataset[0]\n",
        "        c, h, w = x.size()\n",
        "        out = 10\n",
        "        # One of the way to define the neural nets layers\n",
        "        # Experimented with a big Neural net to train more than million\n",
        "        # parameter\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=(3,3), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=(3,3), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=(3,3), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=(3,3), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.fcon = nn.Sequential(\n",
        "            nn.Linear(7 * 7 * 256, 20000),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(20000, 10000),\n",
        "            nn.Linear(10000, 5000),\n",
        "            nn.Linear(5000, 2000),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2000, 500),\n",
        "            nn.Linear(500, out)\n",
        "        )\n",
        "\n",
        "    # Forward pass. Backward pass is automatically implemented\n",
        "    def forward(self, x):\n",
        "        n, c, h, w = x.size()\n",
        "        convout = self.conv(x)\n",
        "        # Need to reshape to get a dense representation for fully \n",
        "        # connected layers\n",
        "        convout = convout.reshape(convout.size(0), -1)\n",
        "        return self.fcon(convout)\n",
        "      \n",
        "      \n",
        "# Defining custom dataset processor\n",
        "class FashionMNISTProcessedDataset(Dataset):\n",
        "    def __init__(self, root, train=True):\n",
        "        self.data = datasets.FashionMNIST(root=root, train=train,\n",
        "            download=True, transform=transforms.ToTensor())\n",
        "        # Identity matrix\n",
        "        self.e = torch.eye(10)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        x, y = self.data[i]\n",
        "        # Only used if we want y as a scalar\n",
        "        # return x, y.unsqueeze(0).float()\n",
        "        # Y as an one hot encoding\n",
        "        #return x, self.e[y].float()\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return 2048 #len(self.data)\n",
        "\n",
        "      \n",
        "# Ploting the train loss   \n",
        "def plot_train_loss(loss):\n",
        "    #x = np.linspace(0, 2, 100)\n",
        "    x = range(len(loss))\n",
        "\n",
        "    plt.plot(x, loss, label='loss')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.title(\"Training Loss per Epoch\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Ploting the train loss   \n",
        "def plot_both_loss(loss, vloss):\n",
        "    #x = np.linspace(0, 2, 100)\n",
        "    x = range(len(loss))\n",
        "\n",
        "    plt.plot(x, loss, label='Training loss')\n",
        "    plt.plot(x, vloss, label='Validatation loss')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.title(\"Losses per Epoch\")\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()    \n",
        "    \n",
        "\n",
        "def validatation_loop():\n",
        "  # Get the validation data and do a forward pass through the neural net\n",
        "  loss_batch = []\n",
        "  for x, y in valid_loader:\n",
        "    # Send both data and lable to cuda\n",
        "    x = x.cuda(async=True)\n",
        "    y = y.cuda(async=True)\n",
        "    # Do the forward pass \n",
        "    y_hat = model(x)\n",
        "    # Compute the loss. Prediction vs Real value\n",
        "    loss = loss_func(y_hat, y)\n",
        "    \n",
        "    # Add the loss to the list\n",
        "    loss_batch.append(loss)\n",
        "    \n",
        "  loss = torch.mean(torch.tensor(loss_batch))\n",
        "  return loss\n",
        "    \n",
        "# Load the training data in this case it Fashionmnist\n",
        "train_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist',train=True)\n",
        "\n",
        "# Load the validation data \n",
        "validatation_dataset = FashionMNISTProcessedDataset(\n",
        "    '/tmp/fashionmnist',train=False)\n",
        "\n",
        "# Build a neural net module passing this dataset\n",
        "#model = Network(train_dataset)\n",
        "model = ConvNetwork(train_dataset)\n",
        "\n",
        "# Make sure that this model runs on cuda\n",
        "model = model.cuda()\n",
        "\n",
        "# Define the loss function. In this case MSELoss\n",
        "loss_func = CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer to use. In this case SGD\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Get the training data in a mini-batch\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64,\n",
        "    shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Get the validatation data in a mini-batch\n",
        "valid_loader = torch.utils.data.DataLoader(validatation_dataset, batch_size=64,\n",
        "    shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Define a list to store all the losses\n",
        "losses = []\n",
        "valid_losses = []\n",
        "\n",
        "# Define a tqdm instance to see the progress bar\n",
        "loop = tqdm(total=len(train_loader)*50, position=0)\n",
        "\n",
        "for epoch in range(50):\n",
        "    # Define a list for batch loss\n",
        "    batch_losses = []\n",
        "    # For each data batch from training data\n",
        "    for batch in train_loader:\n",
        "        # batch[0] is the data and 1 is the label\n",
        "        batch[0]=batch[0].cuda(async=True)\n",
        "        batch[1]=batch[1].cuda(async=True)\n",
        "        \n",
        "        # Reset the grad value to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Predicted value \n",
        "        y_hat = model(batch[0])\n",
        "        \n",
        "        # Compute the loss\n",
        "        loss = loss_func(y_hat, batch[1])\n",
        "        \n",
        "        # Propagate the loss backward. Backprop\n",
        "        loss.backward()\n",
        "        \n",
        "        #print (epoch, loss, loss1)\n",
        "        # Update the weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Set the tqdm params\n",
        "        loop.set_description('loss:{:.4f}'.format(loss.item()))\n",
        "        loop.update(1)\n",
        "        \n",
        "        # Append the loss to compute the average\n",
        "        batch_losses.append(loss)\n",
        "    \n",
        "    # Call the validatation step\n",
        "    valid_loss = validatation_loop()\n",
        "  \n",
        "    # Compute average loss for that batch\n",
        "    loss = torch.mean(torch.tensor(batch_losses))\n",
        "    \n",
        "    # Append the average loss to draw graph\n",
        "    losses.append(loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "# Close the loop display\n",
        "loop.close()\n",
        "\n",
        "# Draw the plot\n",
        "plot_both_loss(losses, valid_losses)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:0.0030: 100%|██████████| 1600/1600 [09:12<00:00,  3.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEVCAYAAAAPRfkLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBQAGIQCAMMV2HHo+puUpwsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f94e38a6f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "H0YjqDFCzbcK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3 Finding Trainable Model Parameters"
      ]
    },
    {
      "metadata": {
        "id": "1Csq9jN07D-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d789365-5b0f-4f8e-c3e0-fb17e6820fc3"
      },
      "cell_type": "code",
      "source": [
        "# model.parameters()\n",
        "value = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print ('Trainable parameters', \"{:,}\".format(value) )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable parameters 512,314,830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8-si5A0a050v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 4 (Parameters Quiz)\n"
      ]
    },
    {
      "metadata": {
        "id": "MYvp4iWl034g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " #### Using a Kernel size of 3×3 what should the settings of your 2d convolution be that results in the following mappings (first answer given to you)\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(3, 3), padding=(0, 0))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) :  (out_channels=22, kernel_size=(3, 3), padding=(1, 1))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=65, h=12, w=12) : (out_channels=65, kernel_size=(3, 3), padding=(2, 2))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=7, h=20, w=20) : (out_channels=7, kernel_size=(3, 3), padding=(6, 6))\n",
        "\n",
        "#### Using a Kernel size of 5×5:\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(5, 5), padding=(1, 1))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) : (out_channels=100, kernel_size=(5, 5), padding=(2, 2))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) : (out_channels=23, kernel_size=(5, 5), padding=(3, 3))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : (out_channels=5, kernel_size=(5, 5), padding=(9, 9)) \n",
        "\n",
        "#### Using Kernel size of 5×3:\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(5, 3), padding=(1, 0))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) : (out_channels=100, kernel_size=(5, 3), padding=(2, 1))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) : (out_channels=23, kernel_size=(5, 3), padding=(3, 2))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : (out_channels=5, kernel_size=(5, 3), padding=(9, 8)) \n",
        "\n",
        "#### Determine the kernel that requires the smallest padding size to make the following mappings possible:\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=9, w=7) :  (out_channels=10, kernel_size=(2, 4), padding=(0, 0))\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) :  (out_channels=22, kernel_size=(1, 1), padding=(0, 0))\n"
      ]
    },
    {
      "metadata": {
        "id": "FoPLMjjy9PjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "f10ab721-1db2-46a4-89a5-8ac65e1e7d20"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Sep 21 22:43:58 2018       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    34W / 149W |      1MiB / 11439MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TGTmkdUR9San",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}